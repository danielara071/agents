# -*- coding: utf-8 -*-
"""Copy of shark-tank-judge-notebook-jupyter.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jIh8TsJ6xPQ7NOHLipRq8IOyzkNmxMbJ

# Shark Tank Judge Agent

This notebook creates a CrewAI agent that acts as a Shark Tank judge, evaluating business pitches and providing feedback.
The judge will communicate with an Entrepreneur agent running in a separate notebook through a single ngrok tunnel hosted here.

## Setup Instructions

### Prerequisites
1. **API Access**: You need either:
   - **OpenAI API Key**: Get one from [platform.openai.com](https://platform.openai.com) OR
   - **Azure OpenAI Service**: Get access from [Azure Portal](https://portal.azure.com)
2. **Ngrok Auth Token**: Sign up at [ngrok.com](https://ngrok.com) and get your auth token

### Running Order
1. Run this Judge notebook first to get the public URL
2. Set up the Entrepreneur notebook with the Judge's URL
3. The Entrepreneur will send its pitch to this Judge notebook
4. Both notebooks will maintain their own conversation history

Let's get started!

## Step 1: Install Required Packages
"""

# Install necessary packages
# This may take a minute to complete
#pip install crewai fastapi uvicorn pyngrok requests openai langchain langchain_openai urllib3 crewai[azure-ai-inference]

"""## Step 2: Import Libraries"""

import os
import requests
import json
import time
from crewai import Agent, Task, Crew, Process, LLM
from fastapi import FastAPI, HTTPException, Request
import uvicorn
from pydantic import BaseModel
import threading
from pyngrok import ngrok
import openai
from langchain_openai import AzureChatOpenAI, ChatOpenAI
from fastapi.middleware.cors import CORSMiddleware
import urllib3
from dotenv import load_dotenv
import os
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

"""## Step 3: Configure API Keys

Select which API you want to use and configure the appropriate settings below.
"""
load_dotenv()
# Choose which API to use: 'openai' or 'azure'
API_TYPE = 'azure'  # Change to 'openai' to use OpenAI

# Ngrok configuration
NGROK_AUTH_TOKEN = os.getenv("NGROK_AUTH_TOKEN") # Replace with your actual ngrok token (already replaced)

# OpenAI configuration (used if API_TYPE = 'openai')
# OPENAI_API_KEY = "YOUR_OPENAI_API_KEY"  # Replace with your actual OpenAI API key
OPENAI_MODEL = "gpt-4"  # or "gpt-3.5-turbo", etc.

# Azure OpenAI configuration (used if API_TYPE = 'azure')
AZURE_API_KEY = os.getenv("AZURE_API_KEY") # "your_azure_api_key"  # Replace with your actual Azure API key
AZURE_ENDPOINT = os.getenv("AZURE_ENDPOINT") # "https://your-resource-name.openai.azure.com/"  # Replace with your actual endpoint
AZURE_DEPLOYMENT = "gpt-4o-mini" # "your-deployment-name"  # Replace with your model deployment name
AZURE_API_VERSION = "2024-12-01-preview"  # Update if using a different API version

# Set ngrok auth token
ngrok.set_auth_token(NGROK_AUTH_TOKEN)

# Configure based on API type
if API_TYPE.lower() == 'openai':
    # Set up for OpenAI
    # os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
    # Define model string for CrewAI LLM
    model_string = OPENAI_MODEL
    print(f"Using OPENAI API with model: {OPENAI_MODEL}")
elif API_TYPE.lower() == 'azure':
    # Set up for Azure OpenAI
    os.environ['AZURE_API_KEY'] = AZURE_API_KEY
    os.environ["AZURE_API_BASE"] = AZURE_ENDPOINT
    os.environ["AZURE_API_VERSION"] = AZURE_API_VERSION
    # Define model string for CrewAI LLM (with azure/ prefix)
    model_string = f"azure/{AZURE_DEPLOYMENT}"
    print(f"Using AZURE OPENAI API with deployment: {AZURE_DEPLOYMENT}")
else:
    raise ValueError("API_TYPE must be either 'openai' or 'azure'")

"""## Step 4: Test API Connection"""

# Create a simple test LLM
test_llm = LLM(model=model_string)

# Create a simple agent
test_agent = Agent(
    role="Tester",
    goal="Test API connection",
    backstory="You are a simple agent created to test the API connection.",
    verbose=True,
    llm=test_llm
)

# Create a simple task
test_task = Task(
    description="Say 'Hello, the connection is working!' Please confirm which API you're using (OpenAI or Azure).",
    expected_output="A confirmation message",
    agent=test_agent
)

# Create a crew with just this agent and task
test_crew = Crew(
    agents=[test_agent],
    tasks=[test_task],
    verbose=1  # Set to verbose to see detailed logs
)

# Run the test
try:
    print("Testing API connection with a simple task...")
    result = test_crew.kickoff()
    print("✅ Connection test successful!")
    print(f"Response: {result}")
    print(f"\n{API_TYPE.upper()} API is properly configured and working!")
except Exception as e:
    print(f"❌ Connection test failed: {str(e)}")
    print("Please check your API keys and configuration.")
    print("Detailed error:", e)

"""## Step 5: Set Up the API and Global Variables"""

# Create FastAPI app for communication
app = FastAPI()

# Add CORS middleware to allow requests from the Entrepreneur notebook
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # For development, you can specify exact origins in production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Define message model
class Message(BaseModel):
    content: str
    sender: str  # 'judge' or 'entrepreneur'

# Initialize a conversation history to store the ongoing discussion
conversation_history = []

"""## Step 6: Create the Judge Agent

Feel free to customize the judge's personality by modifying the backstory.
"""

# Create the Shark Tank Judge Agent
judge_agent = Agent(
    role="Shark Tank Judge",
    goal="Evaluate business pitches critically and decide whether to invest",
    backstory="""You are a successful entrepreneur and investor on Shark Tank.
    You have a keen eye for promising businesses and can quickly identify flaws in business models.
    You are tough but fair, and you always ask penetrating questions about revenue, margins,
    customer acquisition costs, and scaling strategies. You're not afraid to say 'I'm out' if
    the numbers don't add up or if you don't believe in the entrepreneur's ability to execute.""",
    verbose=True,
    allow_delegation=False,
    llm=LLM(model=model_string)
)

judge_agent2 = Agent (
    role="Shark Tank Judge 2",
    goal="Evaluate business pitches with an emphasis on innovation, product design, and long-term potential",
    backstory="""You are a former product designer who became famous for turning niche ideas into massive brands.
    You believe that great products come from understanding people deeply, not just spreadsheets. You get excited
    by bold visions, clever design, and markets that others underestimate.

    You challenge founders on user experience, product-market fit, differentiation, and brand story. You’re warmer
    and more empathetic than the classic Shark Tank judge, but you still expect clarity and honesty. If the founder
    shows true passion and a strong understanding of the customer, you are willing to overlook early business flaws
    and take big bets on transformative ideas.""",
    verbose=True,
    allow_delegation=False,
    llm=LLM(model=model_string)
)

"""## Step 7: Define API Routes"""

# API routes for communication
@app.post("/submit_message")
async def submit_message(message: Message):
    """Endpoint to handle messages from both Judge and Entrepreneur"""
    global conversation_history

    # Add incoming message
    conversation_history.append({"role": message.sender, "content": message.content})
    print(f"Received message from {message.sender}: {message.content}...")

    # If message is from entrepreneur, let the judge respond
    if message.sender.lower() == "entrepreneur":
         # Build context AFTER receiving entrepreneur message
        context = "\n".join([f"{msg['role']}: {msg['content']}" for msg in conversation_history])

        task1 = Task(
            description=f"""Evaluate the entrepreneur's pitch and respond appropriately.

            Conversation history:
            {context}

            Respond with your thoughts, questions or investment decision. Be critical but constructive.
            If you need more information, ask specific questions. If you have enough information,
            make your final investment decision. Tell it as if you were a human, no bulletpoint, just a narrative paragraph""",
            expected_output="Judge 1 evaluation",
            agent=judge_agent,
        )

        crew1 = Crew(agents=[judge_agent], tasks=[task1])
        result1 = crew1.kickoff()
        judge_response = result1.raw

        # Add Judge 1 to history
        conversation_history.append({"role": "Judge 1", "content": judge_response})

        context = "\n".join([f"{msg['role']}: {msg['content']}" for msg in conversation_history])

        task2 = Task(
            description=f"""
            Evaluate the entrepreneur's pitch and respond appropriately.

            Conversation history:
            {context}

            Respond with your thoughts, questions or investment decision. Be critical but constructive.
            If you need more information, ask specific questions. If you have enough information,
            make your final investment decision. Tell it as if you were a human, no bulletpoint, just a narrative paragraph""",
            expected_output="Judge 2 evaluation",
            agent=judge_agent2,
        )

        crew2 = Crew(agents=[judge_agent2], tasks=[task2])
        result2 = crew2.kickoff()
        judge2_response = result2.raw

        # Add Judge 2 to history
        conversation_history.append({"role": "Judge 2", "content": judge2_response})


        # Return BOTH in a format the entrepreneur notebook understands
        return { "status": "success",
                  "messages": [
                  {"response": judge_response, "sender": "Judge 1"},
                  {"response": judge2_response, "sender": "Judge 2"}
                              ]
                }

    # If message is not from entrepreneur
    return {"status": "success", "message": "Message received"}
@app.get("/conversation_history")
async def get_conversation_history():
    """Endpoint to get the full conversation history"""
    return conversation_history

@app.post("/save_conversation")
async def save_conversation_endpoint():
    """Endpoint to save the conversation history to a JSON file"""
    try:
        filename = save_conversation_to_json()
        if filename:
            return {"status": "success", "filename": filename, "message": f"Conversation saved to {filename}"}
        else:
            return {"status": "error", "message": "Failed to save conversation"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

"""## Step 8: Start the Server"""

# Function to start the API server with ngrok
def start_server_with_ngrok():
    """Start the FastAPI server with ngrok tunnel"""
    # Open an ngrok tunnel to the HTTP server
    public_url = ngrok.connect(8000).public_url
    print(f"Server is publicly accessible at: {public_url}")
    print(f"IMPORTANT: Copy this URL and use it in the entrepreneur notebook to connect")

    uvicorn.run(app, host="0.0.0.0", port=8000)

# Start the API server in a separate thread
server_thread = threading.Thread(target=start_server_with_ngrok, daemon=True)
server_thread.start()

# Print instructions
print("Shark Tank Simulation Server is starting...")
print("Waiting for ngrok to establish connection...")
time.sleep(5)  # Give ngrok time to establish connection

print("\n=========== NEXT STEPS ===========")
print("1. Copy the URL shown above")
print("2. Go to the Entrepreneur notebook")
print("3. Paste the URL to connect to this server")
print("4. The Entrepreneur will initiate the pitch from their notebook")
print("=================================")

"""## Step 9: Check Conversation History

Run this cell anytime to see the current conversation between the agents.
"""

# Function to check conversation history
def check_conversation():
    """Display the current conversation history"""
    print("\n=== CONVERSATION HISTORY ===\n")
    for message in conversation_history:
        print(f"-{message['role']}:\n {message['content']}...\n")

    return conversation_history

# Function to save conversation history to JSON file
def save_conversation_to_json(filename=None):
    """Save the conversation history to a JSON file"""
    global conversation_history
    
    if filename is None:
        # Generate filename with timestamp
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"judge_conversation_{timestamp}.json"
    
    # Prepare data to save
    data_to_save = {
        "conversation_history": conversation_history,
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "total_messages": len(conversation_history)
    }
    
    try:
        # Get the full absolute path
        full_path = os.path.abspath(filename)
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data_to_save, f, indent=2, ensure_ascii=False)
        print(f"✅ Conversation saved to: {full_path}")
        return full_path
    except Exception as e:
        print(f"❌ Error saving conversation: {e}")
        return None

# Check the conversation history
check_conversation()

"""## Keep Notebook Active

Run this cell periodically to keep the notebook connection active.
"""

# Run this cell periodically to keep the notebook active
def keep_alive():
    """Keep the notebook connection active"""
    print("Keeping connection alive...")
    print(f"Current time: {time.strftime('%H:%M:%S')}")
    print(f"Current conversation length: {len(conversation_history)} messages")

keep_alive()

"""## Save Conversation to JSON

Run this cell to save the conversation history to a JSON file.
You can also call save_conversation_to_json() with a custom filename.
"""

# Save conversation to JSON file
# save_conversation_to_json()  # Uses auto-generated filename with timestamp
# save_conversation_to_json("my_conversation.json")  # Or specify a custom filename

# Keep the script running
print("\nServer is running. Press Ctrl+C to stop.")
try:
    while True:
        time.sleep(1)
except KeyboardInterrupt:
    print("\nShutting down server...")
    ngrok.kill()  # Close ngrok tunnel